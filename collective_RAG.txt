import streamlit as st
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
import os

# Set your OpenAI API key (replace with your actual key or use environment variable)
os.environ["OPENAI_API_KEY"] = "your API Key"

# Streamlit App UI
st.title("ðŸ¦ Digital Banking RAG Advisor")

# File uploader
st.sidebar.header("ðŸ“‚ Upload Knowledge File")
uploaded_file = st.sidebar.file_uploader("Upload a `.txt` file about digital banking", type="txt")

# Text input for user query
st.subheader("â“ Ask a Question")
user_query = st.text_input("Enter your question (e.g., What are the benefits of digital banking?)")

# Main logic
if uploaded_file and user_query:
    # Save the uploaded file temporarily
    with open("temp_banking.txt", "wb") as f:
        f.write(uploaded_file.read())

    # Load and split the text
    loader = TextLoader("temp_banking.txt")
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = text_splitter.split_documents(documents)

    # Embedding and FAISS vector store
    embeddings = OpenAIEmbeddings()
    db = FAISS.from_documents(split_docs, embeddings)
    retriever = db.as_retriever()

    # RAG QA Chain
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-3.5-turbo", temperature=0),
        retriever=retriever,
        return_source_documents=True
    )

    # Get the answer
    result = qa_chain({"query": user_query})
    answer = result["result"]

    # Display Answer
    st.markdown("### ðŸ’¡ Answer")
    st.write(answer)

    # Evaluate Context Quality
    source_docs = result.get("source_documents", [])
    num_sources = len(source_docs)
    context_quality = (
        "Excellent" if num_sources >= 3 else
        "Good" if num_sources == 2 else
        "Fair" if num_sources == 1 else
        "Poor"
    )

    # Confidence Level Heuristic
    if any(word in answer.lower() for word in ["must", "essential", "critical", "mandatory"]):
        confidence_level = "High"
    elif any(word in answer.lower() for word in ["can", "suggest", "may", "recommended"]):
        confidence_level = "Medium"
    else:
        confidence_level = "Low"

    # Display Evaluation
    st.markdown("### ðŸ“Š Evaluation")
    st.write(f"**Context Quality:** {context_quality}")
    st.write(f"**Confidence Level:** {confidence_level}")

    # Show source content
    with st.expander("ðŸ“š Source Content"):
        for i, doc in enumerate(source_docs):
            st.markdown(f"**Chunk {i+1}:**")
            st.text(doc.page_content)

elif not uploaded_file:
    st.info("ðŸ“Ž Please upload a `.txt` file with digital banking context.")
elif not user_query:
    st.info("ðŸ’¬ Enter a question above to begin.")
